# -*- coding: utf-8 -*-
"""𝓘𝓻𝓲𝓼 𝓕𝓵𝓸𝔀𝓮𝓻 𝓒𝓵𝓪𝓼𝓼𝓲𝓯𝓲𝓬𝓪𝓽𝓲𝓸𝓷

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1akMNI-szL37Sz65XmAnr_FL630FOKL23
"""

from google.colab import drive as dv
dv.mount('/content/drive')

# Ignore Python Script warning
import warnings
warnings.filterwarnings("ignore")

# Commented out IPython magic to ensure Python compatibility.
# import Python packages
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
# %matplotlib inline

DataFrame = pd.read_csv(r'/content/drive/MyDrive/OIBISP/𝕯𝖆𝖙𝖆𝕾𝖈𝖎𝖊𝖓𝖈𝖊/DataSheet/Iris.csv')
DataFrame

DataFrame.head(), DataFrame.tail()

DataFrame.describe()

DataFrame.info()

# Visualize the whole dataset
sns.pairplot(DataFrame, hue= 'Species', diag_kind="hist") # Seaborn Pair-plot

g = sns.pairplot(DataFrame, diag_kind="kde")
g.map_lower(sns.kdeplot, levels=6, color=".2")

print(DataFrame['Species'].unique())

counts = DataFrame['Species'].isin(['Iris-versicolor', 'Iris-virginica', 'Iris-setosa'])
grouped_counts = DataFrame[counts].groupby('Species').size()
NumOfVer = grouped_counts.get('Iris-versicolor', 0)
NumOfVirg = grouped_counts.get('Iris-virginica', 0)
NumOfSetosa = grouped_counts.get('Iris-setosa', 0)

NumOfVer, NumOfVirg, NumOfSetosa

DataFrame.columns

DataFrame.isnull().sum() # check empty and sum by column

DataFrame = DataFrame.drop(columns='Id')
DataFrame

DataFrame['PetalWidthCm'].plot(kind='line', figsize=(8, 4), title='Petal Width')
plt.gca().spines[['top', 'right']].set_visible(False)

DataFrame['PetalLengthCm'].plot(kind='line', figsize=(8, 4), title='Petal Length')
plt.gca().spines[['top', 'right']].set_visible(False)

DataFrame['Species'].value_counts()

# Separate features and target
# Split to X, Y
# X represents the predictors/features/inputs
# Y predicted - target/output
array = DataFrame.values
X = array[:,0:4]
Y = array[:,4]

print(X,'\n',Y)

# Source for help
# [ StackOverFlow, GeeksforGeeks ] ~Map Example
# https://matplotlib.org/stable/plot_types/index.html
# https://matplotlib.org/stable/gallery/pie_and_polar_charts/index.html
Y_Data = np.array([np.average(X[:, i][Y == j].astype('float32')) for i in range(X.shape[1]) for j in np.unique(Y)])
Y_Data_reshaped = Y_Data.reshape(len(np.unique(Y)), -1) # StackOverFlow Example

# Calculate total average values for each class
class_averages = np.sum(Y_Data_reshaped, axis=1)

# Convert to percentage
percentages = class_averages / np.sum(class_averages) * 100

# Colors for each class
colors = ['lightcoral', 'lightgreen', 'lightskyblue']

# Create pie chart
plt.figure(figsize=(5, 5))
plt.pie(percentages, labels=np.unique(Y), colors=colors, autopct='%1.2f%%', startangle=90)

# Draw a circle at the center to make it a donut chart
centre_circle = plt.Circle((0,0),0.70,fc='white')
fig = plt.gcf()
fig.gca().add_artist(centre_circle)

# Set aspect ratio
plt.axis('equal')

# Legend
plt.legend(bbox_to_anchor=(1, 0.5), labels=np.unique(Y), loc="center left")

plt.title('Average Values')
plt.show()

from sklearn.model_selection import train_test_split
# Model Training
# Split the data to train and test dataset.
X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size= 0.3) # 0.3 Using 30% data for test and remanning for training

X_train.shape, X_test.shape

Y_train.shape, Y_test.shape

# Support vector machine algorithm
from sklearn.svm import SVC
svn = SVC()
svn.fit(X_train, Y_train)

# Predict from the test dataset
predictions = svn.predict(X_test)

# Calculate the accuracy
#Confusion matrix
from sklearn.metrics import accuracy_score
svm_score = accuracy_score(Y_test, predictions)
print("Accuracy Score:",accuracy_score(Y_test, predictions))

# A detailed classification report
from sklearn.metrics import classification_report
print(classification_report(Y_test, predictions))

#Using GaussianNB
from sklearn.naive_bayes import GaussianNB
model = GaussianNB()
model.fit(X_train,Y_train)
Y_pred = model.predict(X_test)

from sklearn.metrics import accuracy_score
gnb_score = accuracy_score(Y_test,Y_pred)
print("Accuracy Score:",accuracy_score(Y_test,Y_pred))

#Using Decision Tree
from sklearn.tree import DecisionTreeClassifier
tree = DecisionTreeClassifier(criterion='entropy',random_state=50)
tree.fit(X_train,Y_train)
tree_pred = tree.predict(X_test)

from sklearn.metrics import accuracy_score
dt_score = accuracy_score(Y_test,tree_pred)
print("Accuracy Score:",accuracy_score(Y_test,tree_pred))

#Using KNN Neighbors
from sklearn.neighbors import KNeighborsClassifier
model_n = KNeighborsClassifier(n_neighbors = 10)
model_n.fit(X_train,Y_train)
model_n_pred = model_n.predict(X_test)

from sklearn.metrics import accuracy_score
knn_score = accuracy_score(Y_test,model_n_pred)
print("Accuracy Score:",accuracy_score(Y_test,model_n_pred))

# Creating a DataFrame with the model names and scores
results = pd.DataFrame({
    'Model': ['SVM', 'GnNB', 'DT', 'KNN'],
    'Score': [svm_score, gnb_score, dt_score, knn_score]
})
# Support Vector Machines: SVM
# Using GaussianNB: GnNB
# Decision Tree: DT
# KNN: KNN


# Sorting the DataFrame by 'Score' in descending order
result_df = results.sort_values(by='Score', ascending=False)

# Displaying the top 9 rows of the sorted DataFrame
result_df.head(9)

results.plot(x='Model', y='Score', kind='line', figsize=(8, 4), title='Score')
plt.gca().spines[['top', 'right']].set_visible(False)
plt.show()

# Numeric positions for X-axis
x_positions = range(len(results))

# Colors for each model
colors = ['skyblue', 'orange', 'lightgreen', 'red']

# Bar plot
plt.figure( )
bars = plt.bar(x_positions, results['Score'], color=colors)
plt.title('Model Comparison')
plt.xlabel('Model')
plt.ylabel('Accuracy Score')
plt.ylim(0, 1.2)  # y-axis

# Set x-axis labels
plt.xticks(x_positions, ['SVM', 'GnNB', 'DT', 'KNN'])

# Legend
legend_labels = ['Support Vector Machines', 'Using GaussianNB', 'Decision Tree', 'KNN']
legend_handles = [plt.Rectangle((0, 0), 1, 1, color=color) for color in colors]
plt.legend(legend_handles, legend_labels, loc='upper left', bbox_to_anchor=(1, 1))
plt.show( )

# After few Run all Model gives 100%
# On changing test_size = { 0.1 - 0.9 } Output of each model vary
# On 0.2 train model has perfect accuracy
# In above graph show how much accuracy change can we see
# In above: at some run all model show 100% accuracy at test_size = 0.3

